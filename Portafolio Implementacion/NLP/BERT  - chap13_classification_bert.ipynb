{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9965915,"sourceType":"datasetVersion","datasetId":6130598},{"sourceId":89513707,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"56c031b5","cell_type":"markdown","source":"# Text Classification Using Transformer Networks (BERT)","metadata":{}},{"id":"c40bd59e","cell_type":"markdown","source":"Some initialization:","metadata":{}},{"id":"3afe3bae","cell_type":"code","source":"import random\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\n# enable tqdm in pandas\ntqdm.pandas()\n\n# set to True to use the gpu (if there is one available)\nuse_gpu = True\n\n# select device\ndevice = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\nprint(f'device: {device.type}')\n\n# random seed\nseed = 1122\n\n# set random seed\nif seed is not None:\n    print(f'random seed: {seed}')\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:00:30.506198Z","iopub.execute_input":"2024-11-24T06:00:30.506555Z","iopub.status.idle":"2024-11-24T06:00:33.852036Z","shell.execute_reply.started":"2024-11-24T06:00:30.506493Z","shell.execute_reply":"2024-11-24T06:00:33.851147Z"}},"outputs":[{"name":"stdout","text":"device: cuda\nrandom seed: 1122\n","output_type":"stream"}],"execution_count":1},{"id":"5d3441f3","cell_type":"markdown","source":"Read the train/dev/test datasets and create a HuggingFace `Dataset` object:","metadata":{}},{"id":"c1885c30","cell_type":"code","source":"def read_data(filename):\n    # read csv file\n    df = pd.read_csv(filename, header=None)\n    # add column names\n    df.columns = ['label', 'title', 'description']\n    # make labels zero-based\n    df['label'] -= 1\n    # concatenate title and description, and remove backslashes\n    df['text'] = df['title'] + \" \" + df['description']\n    df['text'] = df['text'].str.replace('\\\\', ' ', regex=False)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:00:33.853710Z","iopub.execute_input":"2024-11-24T06:00:33.854094Z","iopub.status.idle":"2024-11-24T06:00:33.859272Z","shell.execute_reply.started":"2024-11-24T06:00:33.854060Z","shell.execute_reply":"2024-11-24T06:00:33.858242Z"}},"outputs":[],"execution_count":2},{"id":"d03f51a6","cell_type":"code","source":"labels = open('/kaggle/input/classes1/classes.txt').read().splitlines()\ntrain_df = read_data('/kaggle/input/agnews-pytorch-simple-embed-classif-90/AG_NEWS/test.csv')\ntest_df = read_data('/kaggle/input/agnews-pytorch-simple-embed-classif-90/AG_NEWS/test.csv')\ntrain_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:00:33.860290Z","iopub.execute_input":"2024-11-24T06:00:33.860539Z","iopub.status.idle":"2024-11-24T06:00:33.998962Z","shell.execute_reply.started":"2024-11-24T06:00:33.860489Z","shell.execute_reply":"2024-11-24T06:00:33.997883Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"      label                                              title  \\\n0         2                  Fears for T N pension after talks   \n1         3  The Race is On: Second Private Team Sets Launc...   \n2         3      Ky. Company Wins Grant to Study Peptides (AP)   \n3         3      Prediction Unit Helps Forecast Wildfires (AP)   \n4         3        Calif. Aims to Limit Farm-Related Smog (AP)   \n...     ...                                                ...   \n7595      0                                   Around the world   \n7596      1                        Void is filled with Clement   \n7597      1                             Martinez leaves bitter   \n7598      2  5 of arthritis patients in Singapore take Bext...   \n7599      2                             EBay gets into rentals   \n\n                                            description  \\\n0     Unions representing workers at Turner   Newall...   \n1     SPACE.com - TORONTO, Canada -- A second\\team o...   \n2     AP - A company founded by a chemistry research...   \n3     AP - It's barely dawn when Mike Fitzpatrick st...   \n4     AP - Southern California's smog-fighting agenc...   \n...                                                 ...   \n7595  Ukrainian presidential candidate Viktor Yushch...   \n7596  With the supply of attractive pitching options...   \n7597  Like Roger Clemens did almost exactly eight ye...   \n7598  SINGAPORE : Doctors in the United States have ...   \n7599  EBay plans to buy the apartment and home renta...   \n\n                                                   text  \n0     Fears for T N pension after talks Unions repre...  \n1     The Race is On: Second Private Team Sets Launc...  \n2     Ky. Company Wins Grant to Study Peptides (AP) ...  \n3     Prediction Unit Helps Forecast Wildfires (AP) ...  \n4     Calif. Aims to Limit Farm-Related Smog (AP) AP...  \n...                                                 ...  \n7595  Around the world Ukrainian presidential candid...  \n7596  Void is filled with Clement With the supply of...  \n7597  Martinez leaves bitter Like Roger Clemens did ...  \n7598  5 of arthritis patients in Singapore take Bext...  \n7599  EBay gets into rentals EBay plans to buy the a...  \n\n[7600 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>title</th>\n      <th>description</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Fears for T N pension after talks</td>\n      <td>Unions representing workers at Turner   Newall...</td>\n      <td>Fears for T N pension after talks Unions repre...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>The Race is On: Second Private Team Sets Launc...</td>\n      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n      <td>The Race is On: Second Private Team Sets Launc...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n      <td>AP - A company founded by a chemistry research...</td>\n      <td>Ky. Company Wins Grant to Study Peptides (AP) ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n      <td>Prediction Unit Helps Forecast Wildfires (AP) ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n      <td>AP - Southern California's smog-fighting agenc...</td>\n      <td>Calif. Aims to Limit Farm-Related Smog (AP) AP...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7595</th>\n      <td>0</td>\n      <td>Around the world</td>\n      <td>Ukrainian presidential candidate Viktor Yushch...</td>\n      <td>Around the world Ukrainian presidential candid...</td>\n    </tr>\n    <tr>\n      <th>7596</th>\n      <td>1</td>\n      <td>Void is filled with Clement</td>\n      <td>With the supply of attractive pitching options...</td>\n      <td>Void is filled with Clement With the supply of...</td>\n    </tr>\n    <tr>\n      <th>7597</th>\n      <td>1</td>\n      <td>Martinez leaves bitter</td>\n      <td>Like Roger Clemens did almost exactly eight ye...</td>\n      <td>Martinez leaves bitter Like Roger Clemens did ...</td>\n    </tr>\n    <tr>\n      <th>7598</th>\n      <td>2</td>\n      <td>5 of arthritis patients in Singapore take Bext...</td>\n      <td>SINGAPORE : Doctors in the United States have ...</td>\n      <td>5 of arthritis patients in Singapore take Bext...</td>\n    </tr>\n    <tr>\n      <th>7599</th>\n      <td>2</td>\n      <td>EBay gets into rentals</td>\n      <td>EBay plans to buy the apartment and home renta...</td>\n      <td>EBay gets into rentals EBay plans to buy the a...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7600 rows Ã— 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"id":"e7518aa0","cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, eval_df = train_test_split(train_df, train_size=0.9)\ntrain_df.reset_index(inplace=True, drop=True)\neval_df.reset_index(inplace=True, drop=True)\n\nprint(f'train rows: {len(train_df.index):,}')\nprint(f'eval rows: {len(eval_df.index):,}')\nprint(f'test rows: {len(test_df.index):,}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:00:34.001370Z","iopub.execute_input":"2024-11-24T06:00:34.001796Z","iopub.status.idle":"2024-11-24T06:00:34.527309Z","shell.execute_reply.started":"2024-11-24T06:00:34.001757Z","shell.execute_reply":"2024-11-24T06:00:34.526358Z"}},"outputs":[{"name":"stdout","text":"train rows: 6,840\neval rows: 760\ntest rows: 7,600\n","output_type":"stream"}],"execution_count":4},{"id":"e06f040b","cell_type":"code","source":"from datasets import Dataset, DatasetDict\n\nds = DatasetDict()\nds['train'] = Dataset.from_pandas(train_df)\nds['validation'] = Dataset.from_pandas(eval_df)\nds['test'] = Dataset.from_pandas(test_df)\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:00:34.528364Z","iopub.execute_input":"2024-11-24T06:00:34.528810Z","iopub.status.idle":"2024-11-24T06:00:35.394989Z","shell.execute_reply.started":"2024-11-24T06:00:34.528783Z","shell.execute_reply":"2024-11-24T06:00:35.393944Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'title', 'description', 'text'],\n        num_rows: 6840\n    })\n    validation: Dataset({\n        features: ['label', 'title', 'description', 'text'],\n        num_rows: 760\n    })\n    test: Dataset({\n        features: ['label', 'title', 'description', 'text'],\n        num_rows: 7600\n    })\n})"},"metadata":{}}],"execution_count":5},{"id":"ac23185a","cell_type":"markdown","source":"Tokenize the texts:","metadata":{}},{"id":"65e8d986","cell_type":"code","source":"from transformers import AutoTokenizer\n\ntransformer_name = 'bert-base-cased'\ntokenizer = AutoTokenizer.from_pretrained(transformer_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:00:35.395850Z","iopub.execute_input":"2024-11-24T06:00:35.396288Z","iopub.status.idle":"2024-11-24T06:00:37.277409Z","shell.execute_reply.started":"2024-11-24T06:00:35.396261Z","shell.execute_reply":"2024-11-24T06:00:37.276488Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdee749d377d4f029a16ded4a306d370"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0abf2eabf3a6427cbe742096b5295eee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"394a63235c6c44eab02843a40d6ad24f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c03cc75105c4e7dba040375a215d8c6"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":6},{"id":"52a2caf5","cell_type":"code","source":"def tokenize(examples):\n    return tokenizer(examples['text'], truncation=True)\n\ntrain_ds = ds['train'].map(\n    tokenize, batched=True,\n    remove_columns=['title', 'description', 'text'],\n)\neval_ds = ds['validation'].map(\n    tokenize,\n    batched=True,\n    remove_columns=['title', 'description', 'text'],\n)\ntrain_ds.to_pandas()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:00:37.278700Z","iopub.execute_input":"2024-11-24T06:00:37.279278Z","iopub.status.idle":"2024-11-24T06:00:38.081554Z","shell.execute_reply.started":"2024-11-24T06:00:37.279238Z","shell.execute_reply":"2024-11-24T06:00:38.080566Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6840 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"918237fffa134529bb3920f80e66978a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa29f3b5b68d4b62a8edaa69ff0413e1"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"      label                                          input_ids  \\\n0         0  [101, 6304, 4250, 11289, 1111, 11501, 1179, 56...   \n1         0  [101, 7414, 1106, 3295, 1248, 1586, 12215, 110...   \n2         1  [101, 143, 23140, 1874, 7187, 1135, 5630, 1556...   \n3         1  [101, 5230, 6331, 125, 13120, 123, 5230, 6331,...   \n4         0  [101, 11917, 8914, 119, 16725, 3225, 4326, 131...   \n...     ...                                                ...   \n6835      1  [101, 13030, 1306, 1431, 1619, 8772, 1795, 130...   \n6836      1  [101, 1478, 1237, 5308, 1929, 1717, 1203, 1365...   \n6837      2  [101, 13212, 2924, 12148, 1324, 5063, 7004, 29...   \n6838      3  [101, 8410, 11147, 9804, 21359, 1513, 8178, 58...   \n6839      2  [101, 5058, 8204, 1116, 1120, 1362, 112, 188, ...   \n\n                                         token_type_ids  \\\n0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n...                                                 ...   \n6835  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n6836  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n6837  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n6838  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n6839  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n\n                                         attention_mask  \n0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n...                                                 ...  \n6835  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n6836  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n6837  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n6838  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n6839  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n\n[6840 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>input_ids</th>\n      <th>token_type_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[101, 6304, 4250, 11289, 1111, 11501, 1179, 56...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>[101, 7414, 1106, 3295, 1248, 1586, 12215, 110...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>[101, 143, 23140, 1874, 7187, 1135, 5630, 1556...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>[101, 5230, 6331, 125, 13120, 123, 5230, 6331,...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>[101, 11917, 8914, 119, 16725, 3225, 4326, 131...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6835</th>\n      <td>1</td>\n      <td>[101, 13030, 1306, 1431, 1619, 8772, 1795, 130...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>6836</th>\n      <td>1</td>\n      <td>[101, 1478, 1237, 5308, 1929, 1717, 1203, 1365...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>6837</th>\n      <td>2</td>\n      <td>[101, 13212, 2924, 12148, 1324, 5063, 7004, 29...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>6838</th>\n      <td>3</td>\n      <td>[101, 8410, 11147, 9804, 21359, 1513, 8178, 58...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>6839</th>\n      <td>2</td>\n      <td>[101, 5058, 8204, 1116, 1120, 1362, 112, 188, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>6840 rows Ã— 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"id":"cca78a0b","cell_type":"markdown","source":"Create the transformer model:","metadata":{}},{"id":"36846278","cell_type":"code","source":"from torch import nn\nfrom transformers.modeling_outputs import SequenceClassifierOutput\nfrom transformers.models.bert.modeling_bert import BertModel, BertPreTrainedModel\n\n# https://github.com/huggingface/transformers/blob/65659a29cf5a079842e61a63d57fa24474288998/src/transformers/models/bert/modeling_bert.py#L1486\n\nclass BertForSequenceClassification(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        self.num_labels = config.num_labels\n        self.bert = BertModel(config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n        self.init_weights()\n        \n    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n        outputs = self.bert(\n            input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            **kwargs,\n        )\n        cls_outputs = outputs.last_hidden_state[:, 0, :]\n        cls_outputs = self.dropout(cls_outputs)\n        logits = self.classifier(cls_outputs)\n        loss = None\n        if labels is not None:\n            loss_fn = nn.CrossEntropyLoss()\n            loss = loss_fn(logits, labels)\n        return SequenceClassifierOutput(\n            loss=loss,\n            logits=logits,\n            hidden_states=outputs.hidden_states,\n            attentions=outputs.attentions,\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:00:38.082700Z","iopub.execute_input":"2024-11-24T06:00:38.082973Z","iopub.status.idle":"2024-11-24T06:00:38.565855Z","shell.execute_reply.started":"2024-11-24T06:00:38.082946Z","shell.execute_reply":"2024-11-24T06:00:38.565160Z"}},"outputs":[],"execution_count":8},{"id":"b15ac966","cell_type":"code","source":"from transformers import AutoConfig\n\nconfig = AutoConfig.from_pretrained(\n    transformer_name,\n    num_labels=len(labels),\n)\n\nmodel = (\n    BertForSequenceClassification\n    .from_pretrained(transformer_name, config=config)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:00:38.566853Z","iopub.execute_input":"2024-11-24T06:00:38.567300Z","iopub.status.idle":"2024-11-24T06:00:40.952183Z","shell.execute_reply.started":"2024-11-24T06:00:38.567272Z","shell.execute_reply":"2024-11-24T06:00:40.951551Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e332cf6fe2245f18cfd407e4d1f94d4"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":9},{"id":"cae1a93c","cell_type":"markdown","source":"Create the trainer object and train:","metadata":{}},{"id":"6d805f81","cell_type":"code","source":"from transformers import TrainingArguments\n\nnum_epochs = 2\nbatch_size = 24\nweight_decay = 0.01\nmodel_name = f'{transformer_name}-sequence-classification'\n\ntraining_args = TrainingArguments(\n    output_dir=model_name,\n    log_level='error',\n    num_train_epochs=num_epochs,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    evaluation_strategy='epoch',\n    weight_decay=weight_decay,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:00:40.956337Z","iopub.execute_input":"2024-11-24T06:00:40.957086Z","iopub.status.idle":"2024-11-24T06:00:51.985871Z","shell.execute_reply.started":"2024-11-24T06:00:40.957049Z","shell.execute_reply":"2024-11-24T06:00:51.984956Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":10},{"id":"77a0699b","cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ndef compute_metrics(eval_pred):\n    y_true = eval_pred.label_ids\n    y_pred = np.argmax(eval_pred.predictions, axis=-1)\n    return {'accuracy': accuracy_score(y_true, y_pred)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:00:51.987158Z","iopub.execute_input":"2024-11-24T06:00:51.987773Z","iopub.status.idle":"2024-11-24T06:00:51.992699Z","shell.execute_reply.started":"2024-11-24T06:00:51.987741Z","shell.execute_reply":"2024-11-24T06:00:51.991595Z"}},"outputs":[],"execution_count":11},{"id":"6c16ead2","cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_ds,\n    eval_dataset=eval_ds,\n    tokenizer=tokenizer,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:00:51.993798Z","iopub.execute_input":"2024-11-24T06:00:51.994139Z","iopub.status.idle":"2024-11-24T06:00:52.988297Z","shell.execute_reply.started":"2024-11-24T06:00:51.994113Z","shell.execute_reply":"2024-11-24T06:00:52.987556Z"}},"outputs":[],"execution_count":12},{"id":"301aefd9","cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:00:52.989468Z","iopub.execute_input":"2024-11-24T06:00:52.989820Z","iopub.status.idle":"2024-11-24T06:05:24.153884Z","shell.execute_reply.started":"2024-11-24T06:00:52.989786Z","shell.execute_reply":"2024-11-24T06:05:24.153086Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113919866666164, max=1.0â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39e2bc73a7a74770ae46c2c912d4d4d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241124_060208-ywxb4wyu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/a00835194-tecnol-gico-de-monterrey/huggingface/runs/ywxb4wyu' target=\"_blank\">bert-base-cased-sequence-classification</a></strong> to <a href='https://wandb.ai/a00835194-tecnol-gico-de-monterrey/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/a00835194-tecnol-gico-de-monterrey/huggingface' target=\"_blank\">https://wandb.ai/a00835194-tecnol-gico-de-monterrey/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/a00835194-tecnol-gico-de-monterrey/huggingface/runs/ywxb4wyu' target=\"_blank\">https://wandb.ai/a00835194-tecnol-gico-de-monterrey/huggingface/runs/ywxb4wyu</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='286' max='286' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [286/286 03:10, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.219481</td>\n      <td>0.922368</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.223616</td>\n      <td>0.921053</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=286, training_loss=0.2752244855974104, metrics={'train_runtime': 269.9403, 'train_samples_per_second': 50.678, 'train_steps_per_second': 1.059, 'total_flos': 952890242353920.0, 'train_loss': 0.2752244855974104, 'epoch': 2.0})"},"metadata":{}}],"execution_count":13},{"id":"0a1ec029","cell_type":"markdown","source":"Evaluate on the test partition:","metadata":{}},{"id":"fa4b892f","cell_type":"code","source":"test_ds = ds['test'].map(\n    tokenize,\n    batched=True,\n    remove_columns=['title', 'description', 'text'],\n)\ntest_ds.to_pandas()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:05:24.155290Z","iopub.execute_input":"2024-11-24T06:05:24.155621Z","iopub.status.idle":"2024-11-24T06:05:24.928720Z","shell.execute_reply.started":"2024-11-24T06:05:24.155591Z","shell.execute_reply":"2024-11-24T06:05:24.927640Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a9f92261ef24a139f21eed5b45090ee"}},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"      label                                          input_ids  \\\n0         2  [101, 11284, 1116, 1111, 157, 151, 12966, 1170...   \n1         3  [101, 1109, 6398, 1110, 1212, 131, 2307, 7219,...   \n2         3  [101, 148, 1183, 119, 1881, 16387, 1116, 4468,...   \n3         3  [101, 11689, 15906, 6115, 12056, 1116, 1370, 2...   \n4         3  [101, 11917, 8914, 119, 19294, 4206, 1106, 215...   \n...     ...                                                ...   \n7595      0  [101, 5596, 1103, 1362, 5284, 5200, 3234, 1384...   \n7596      1  [101, 159, 7874, 1110, 2709, 1114, 13875, 1556...   \n7597      1  [101, 16247, 2972, 9178, 2409, 4271, 140, 1418...   \n7598      2  [101, 126, 1104, 1893, 8167, 10721, 4420, 1107...   \n7599      2  [101, 142, 2064, 4164, 3370, 1154, 13519, 1116...   \n\n                                         token_type_ids  \\\n0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n...                                                 ...   \n7595  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n7596  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n7597  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n7598  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n7599  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n\n                                         attention_mask  \n0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n...                                                 ...  \n7595  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n7596  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n7597  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n7598  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n7599  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n\n[7600 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>input_ids</th>\n      <th>token_type_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>[101, 11284, 1116, 1111, 157, 151, 12966, 1170...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>[101, 1109, 6398, 1110, 1212, 131, 2307, 7219,...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>[101, 148, 1183, 119, 1881, 16387, 1116, 4468,...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>[101, 11689, 15906, 6115, 12056, 1116, 1370, 2...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>[101, 11917, 8914, 119, 19294, 4206, 1106, 215...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7595</th>\n      <td>0</td>\n      <td>[101, 5596, 1103, 1362, 5284, 5200, 3234, 1384...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>7596</th>\n      <td>1</td>\n      <td>[101, 159, 7874, 1110, 2709, 1114, 13875, 1556...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>7597</th>\n      <td>1</td>\n      <td>[101, 16247, 2972, 9178, 2409, 4271, 140, 1418...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>7598</th>\n      <td>2</td>\n      <td>[101, 126, 1104, 1893, 8167, 10721, 4420, 1107...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>7599</th>\n      <td>2</td>\n      <td>[101, 142, 2064, 4164, 3370, 1154, 13519, 1116...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7600 rows Ã— 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":14},{"id":"7fe018fd","cell_type":"code","source":"output = trainer.predict(test_ds)\noutput","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:05:24.929986Z","iopub.execute_input":"2024-11-24T06:05:24.930264Z","iopub.status.idle":"2024-11-24T06:06:00.766833Z","shell.execute_reply.started":"2024-11-24T06:05:24.930237Z","shell.execute_reply":"2024-11-24T06:06:00.765784Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"PredictionOutput(predictions=array([[-0.91912985, -2.5064373 ,  5.027797  , -2.0299542 ],\n       [-1.2531306 , -2.7895691 , -1.6978292 ,  5.2996116 ],\n       [-0.15892984, -3.4823432 , -1.323707  ,  4.309913  ],\n       ...,\n       [-2.507629  ,  6.033808  , -1.5759811 , -2.46763   ],\n       [-0.93429077, -2.1622527 ,  2.9386559 , -0.24829237],\n       [-2.004243  , -3.3836584 ,  2.7005377 ,  2.3383913 ]],\n      dtype=float32), label_ids=array([2, 3, 3, ..., 1, 2, 2]), metrics={'test_loss': 0.10480492562055588, 'test_accuracy': 0.9669736842105263, 'test_runtime': 35.8235, 'test_samples_per_second': 212.151, 'test_steps_per_second': 4.438})"},"metadata":{}}],"execution_count":15},{"id":"14221494","cell_type":"code","source":"from sklearn.metrics import classification_report\n\ny_true = output.label_ids\ny_pred = np.argmax(output.predictions, axis=-1)\ntarget_names = labels\nprint(classification_report(y_true, y_pred, target_names=target_names))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:06:00.768047Z","iopub.execute_input":"2024-11-24T06:06:00.768388Z","iopub.status.idle":"2024-11-24T06:06:00.786139Z","shell.execute_reply.started":"2024-11-24T06:06:00.768357Z","shell.execute_reply":"2024-11-24T06:06:00.785226Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n       World       0.98      0.96      0.97      1900\n      Sports       0.99      1.00      0.99      1900\n    Business       0.96      0.94      0.95      1900\n    Sci/Tech       0.94      0.97      0.95      1900\n\n    accuracy                           0.97      7600\n   macro avg       0.97      0.97      0.97      7600\nweighted avg       0.97      0.97      0.97      7600\n\n","output_type":"stream"}],"execution_count":16}]}